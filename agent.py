# just need an interface for the agent
from task import Task
import os
import openai
import anthropic
import together
import json
import azure

class BaseLM:
    """
    A base class for language models from a configuration file.
    """

    def __init__(
        self,
        provider: str,
        model_name: str,
        api_key: str,
        max_tokens: int = 1024,
        temperature: float = 0.7,
        **kwargs
    ):
        """
        Initialize the language model.

        :param provider: Provider name (e.g. "openai", "anthropic", "together").
        :param model_name: Model name (e.g. "gpt-3.5-turbo").
        :param api_key: API key for authenticating requests.
        :param max_tokens: The maximum number of tokens in the generated response.
        :param temperature: The sampling temperature for generation.
        :param kwargs: Any additional keyword arguments that might be relevant 
                       to a specific provider (e.g. "top_p", "top_k", etc.).
        """
        self.provider = provider.lower()
        self.model_name = model_name
        self.api_key = api_key
        self.max_tokens = max_tokens
        self.temperature = temperature
        self.extra_params = kwargs
        self.client = None

        if self.provider == "openai":
            self._init_openai()
        elif self.provider == "anthropic":
            self._init_anthropic()
        elif self.provider == "together":
            self._init_together()
        elif self.provider == "azure":
            self._init_azure()
        else:
            raise ValueError(f"Unsupported provider: {self.provider}")

    def _init_azure(self):
        """
        Initialize Azure client from API key.
        """
        self.client = azure.OpenAI(api_key=self.api_key)


    def _init_openai(self):
        """
        Initialize the OpenAI client from API key. 
        """
        openai.api_key = self.api_key
        self.client = openai.OpenAI(api_key=self.api_key)

    def _init_anthropic(self):
        """
        Initialize the Anthropic client using your API key.
        """
        try:
            import anthropic
            # Typically something like:
            # self.anthropic_client = anthropic.Client(api_key=self.api_key)
            # Actual usage may differ based on Anthropics’s official package.
        except ImportError:
            raise ImportError("Please install the Anthropic package (pip install anthropic).")

    def _init_together(self):
        """
        Initialize the Together client using your API key.
        """
        try:
            import together
            # Typically something like:
            # together.api_key = self.api_key
            # Actual usage may differ based on Together’s official package.
        except ImportError:
            raise ImportError("Please install the Together package (pip install together).")

    def generate_text(self, prompt: str) -> str:
        """
        Generate text based on the given prompt using the configured provider and model.

        :param prompt: The text prompt for the model.
        :return: The generated text as a string.
        """
        if self.provider == "openai":
            return self._generate_openai(prompt)
        elif self.provider == "anthropic":
            return self._generate_anthropic(prompt)
        elif self.provider == "together":
            return self._generate_together(prompt)
        else:
            raise ValueError(f"Unsupported provider: {self.provider}")

    def _generate_openai(self, prompt: str) -> str:
        """
        Generate text using OpenAI.
        """

        response = openai.ChatCompletion.create(
            model=self.model_name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=self.max_tokens,
            temperature=self.temperature,
            **self.extra_params
        )
        # This example is for ChatCompletion; adapt if using another endpoint.
        return response['choices'][0]['message']['content']

    def _generate_anthropic(self, prompt: str) -> str:
        """
        Generate text using Anthropic API.
        """
        client = anthropic.Client(api_key=self.api_key)
        response = client.completions.create(
            prompt=f"{anthropic.HUMAN_PROMPT} {prompt}{anthropic.AI_PROMPT}",
            model=self.model_name,
            max_tokens_to_sample=self.max_tokens,
            temperature=self.temperature,
            **self.extra_params
        )
        return response.completion

    def _generate_together(self, prompt: str) -> str:
        """
        Generate text using Together API.
        """
        result = together.Completion.create(
            model=self.model_name,
            prompt=prompt,
            max_tokens=self.max_tokens,
            temperature=self.temperature,
            **self.extra_params
        )
        return result.content

    @classmethod
    def from_config(cls, config_path: str):
        """
        Instatntiate from a JSON config file.

        :param config_path: Path to the JSON config file.
        :return: An instance of BaseLM (or a subclass, if you'd prefer).
        """
        if not os.path.isfile(config_path):
            raise FileNotFoundError(f"Config file not found: {config_path}")

        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        return cls(**config)


# Example usage (if you have a config.json):
model = BaseLM.from_config("config.json")
output = model.generate_text("Hello, can you tell me a joke?")
print(output)
