{
    "task_id": "learn_2dae",
    "paper_id": "chandra_representation",
    "kind": "numeric",
    "difficulty": 5,
    "description": "Reproduce the 2D-AE embedding space",
    "instructions": [
        "1. Load the 'eventfiles_table.csv' file containing preprocessed Chandra event files from the dataset.",
        "2. Filter the event files to include only photon events with energies in the range 0.5-7 keV, corresponding to the broad energy band sensitivity of Chandra's ACIS instrument as specified in \\ref{sec:datarepp}.",
        "3. Build E-t maps (2D eventfile representations) for each event file following the methodology in \\ref{sec:datarepp}: (a) Create normalized time column $\\boldsymbol{\\tau} = \\frac{\\boldsymbol{t} - t_{1}}{T}$ where $T = t_N - t_1$ is the event file duration, (b) Create log-energy column $\\boldsymbol{\\epsilon} = \\log \\boldsymbol{E}$, (c) Bin the events into 2D histograms with dimensions $(n_{\\tau}, n_{\\epsilon}) = (24, 16)$ as determined in \\ref{sec:datarepp}.",
        "4. Normalize the histogram values in each E-t map by dividing each bin count by the total number of events in that event file to create probability distributions.",
        "5. Flatten each 2D E-t map into a feature vector of length $n = n_{\\tau} \\cdot n_{\\epsilon} = 384$ to create the input matrix $\\mathbf{X}$ of size $(m, 384)$ where $m$ is the number of event files.",
        "6. Download the pre-trained encoder from the GitHub repository https://github.com/StevenDillmann/ml-xraytransients-mnras/blob/main/encoders/encoder_et.h5 using TensorFlow/Keras.",
        "7. Apply the trained encoder to extract features from the E-t maps, transforming the input matrix $\\mathbf{X}$ to the latent feature space $\\mathbf{X_{ae}}$ with $n_{ae} = 12$ dimensions as specified in \\ref{sec:features}.",
        "8. Apply t-SNE dimensionality reduction to the extracted features using the hyperparameters from \\ref{sec:methods}: perplexity=40, learning_rate=100, n_iter=3000, early_exaggeration=1, init='random', random_state=2412.",
        "9. Transform the high-dimensional features to a 2D embedding space $\\mathbf{Z}$ of size $(m, 2)$ using the t-SNE algorithm.",
        "10. Load the original embedding space from '../data/chandra_representation_embeddings/paper2DAE_embedding.csv' containing columns: tsne1, tsne2, obsreg_id.",
        "11. Match the obsreg_id values between your computed embedding and the original embedding to ensure proper correspondence between data points.",
        "12. Extract the tsne1 and tsne2 coordinate vectors from both your computed embedding and the original embedding, ensuring they are in the same order based on obsreg_id matching.",
        "13. Perform Procrustes analysis between your computed t-SNE embedding vectors and the original embedding vectors (tsne1, tsne2 columns) using scipy.spatial.procrustes or equivalent function.",
        "14. Compute the Procrustes disparity value from the Procrustes analysis, which measures the dissimilarity between the two embedding spaces.",
        "15. Calculate the final similarity score as $1 - \\text{procrustes_disparity}$, where values close to 1 indicate high similarity and values close to 0 indicate low similarity.",
        "16. Return the computed similarity score as the final result."
    ],
    "tolerance": 0.05,
    "expected_output": 1.0
}